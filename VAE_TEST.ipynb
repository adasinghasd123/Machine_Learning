{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adasinghasd123/Machine_Learning/blob/main/VAE_TEST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing the required package\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf; tf.compat.v1.disable_eager_execution()\n",
        "from keras import backend as K\n",
        "from keras.layers import Input, Dense, Conv2D, Conv2DTranspose, Flatten, Lambda, Reshape\n",
        "from keras.models import Model\n",
        "from keras.losses import binary_crossentropy\n",
        "\n",
        "#importing the dataset from keras\n",
        "from keras.datasets import mnist\n",
        "\n",
        "\n",
        "np.random.seed(25)\n",
        "tf.executing_eagerly()"
      ],
      "metadata": {
        "id": "-D9ZaZr2YUZS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d19195f9-afb6-455f-ce20-824e2819db14"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#toring the dataset in X_train and X_test\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4woiVuOTqyu",
        "outputId": "0655f8f7-38b7-4844-d39d-dfbc2df8c16e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#show images at index 130 to 139 taken from X_train array\n",
        "fig, axes = plt.subplots(ncols=10, sharex=False,\n",
        "    sharey=True, figsize=(20, 7))\n",
        "counter = 0\n",
        "for i in range(130, 140):\n",
        "    axes[counter].set_title(y_train[i])\n",
        "    axes[counter].imshow(X_train[i], cmap='gray')\n",
        "    axes[counter].get_xaxis().set_visible(False)\n",
        "    axes[counter].get_yaxis().set_visible(False)\n",
        "    counter += 1\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "mkjH4BtCTuCs",
        "outputId": "e9c8e179-579b-4860-b51c-cdd447ed66e5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x504 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkXQy2AfT6c_",
        "outputId": "817b2c43-e99a-4b5c-af07-a243b21664c4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ztz4TV24U2NX",
        "outputId": "81c4f4c9-0cfc-4fac-8825-abd7716361e7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_xWsWRYVCJM",
        "outputId": "ecf11ce9-1c5b-4d34-9aa1-820c8766ee7b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hvwr3_R7VGdi",
        "outputId": "15545004-44ba-420b-ba21-a8c9d5cd8605"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#normalize the pixel in range of 0 to 1 instead of 0 to 255\n",
        "X_train = X_train/255\n",
        "X_test = X_test/255   "
      ],
      "metadata": {
        "id": "qz8vXtQXVJLL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d80WhJRKVN5-",
        "outputId": "bb10f335-64bb-4b50-c259-5caf8c6452bc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert from (no_of_data, 28, 28) to (no_of_data, 28, 28, 1)\n",
        "X_train_new = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
        "X_test_new = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)"
      ],
      "metadata": {
        "id": "9RUHe4DOVgxN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_new.shape)\n",
        "print(X_test_new.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jM4d_BaZWDAs",
        "outputId": "9bd1c4d4-a2e0-453e-d317-ba394b96a9d4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now we are going to construct VAE architecture**"
      ],
      "metadata": {
        "id": "M7TIrdh-WfCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Constructing encoder\n",
        "\n",
        "#defining some variables\n",
        "img_height   = X_train_new.shape[1]    # 28\n",
        "img_width    = X_train_new.shape[2]    # 28\n",
        "num_channels = X_train_new.shape[3]    # 1\n",
        "input_shape =  (img_height, img_width, num_channels)   # (28,28,1)\n",
        "latent_dim = 2    # Dimension of the latent space"
      ],
      "metadata": {
        "id": "WV2kcWGgWONE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.using Sequential API\n",
        "Here we create the model layer-by-layer. It is very simple and easy to use. But sharing of layers or branching of layers is not allowed (We will see what sharing or branching means later). Also, you canâ€™t have multiple inputs or outputs.\n",
        "\n",
        "---\n",
        "   2.using Functional API\n",
        "It is more flexible than the sequential API. It is more powerful than the sequential API in the sense branching or sharing of layers is allowed here. And also it can have multiple inputs and outputs.\n"
      ],
      "metadata": {
        "id": "jUBMBMWrXH5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we are using Functioanl approach\n",
        "\n",
        "\n",
        "#input layer\n",
        "encoder_input = Input(shape=input_shape)\n",
        "\n",
        "# 2 convolution layers\n",
        "encoder_conv = Conv2D(filters=8, kernel_size=3, strides=2, \n",
        "                padding='same', activation='relu')(encoder_input)\n",
        "encoder_conv = Conv2D(filters=16, kernel_size=3, strides=2, \n",
        "                padding='same', activation='relu')(encoder_input)\n",
        "\n",
        "# Flatten layer to reshape all data into a single one-dimensional array\n",
        "encoder = Flatten()(encoder_conv)\n",
        "\n",
        "# now connected to mu and sigma layer, each  having 2 neurons\n",
        "mu = Dense(latent_dim)(encoder)\n",
        "sigma = Dense(latent_dim)(encoder)"
      ],
      "metadata": {
        "id": "vv96HlfuW0i-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now we need to  define a function called compute_latent() which is going to be used to determine the values in the latent space layer.\n",
        "\n",
        "def compute_latent(x):\n",
        "    mu, sigma = x\n",
        "    batch = K.shape(mu)[0]\n",
        "    dim = K.int_shape(mu)[1]\n",
        "    eps = K.random_normal(shape=(batch,dim))\n",
        "    return mu + K.exp(sigma/2)*eps"
      ],
      "metadata": {
        "id": "RLvXsfC1XXBr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lambda layer\n",
        "#reparameterization trick\n",
        "\n",
        "latent_space = Lambda(compute_latent, output_shape=(latent_dim,))([mu, sigma])"
      ],
      "metadata": {
        "id": "rgRqL0-oYYrh"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#shape of convolution layer in conv_shape\n",
        "conv_shape = K.int_shape(encoder_conv)\n",
        "print(conv_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFSgzRGVZACJ",
        "outputId": "46403d2d-2336-4c9b-a0c9-973ce7df774e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 14, 14, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Constructing decoder\n",
        "\n",
        "decoder_input = Input(shape=(latent_dim,))\n",
        "decoder = Dense(conv_shape[1]*conv_shape[2]*conv_shape[3], activation='relu')(decoder_input)\n",
        "decoder = Reshape((conv_shape[1], conv_shape[2], conv_shape[3]))(decoder)\n",
        "\n",
        "#Conv2DTranspose for inverse transformation of the standard Conv2D layer\n",
        "decoder_conv = Conv2DTranspose(filters=16, kernel_size=3, strides=2, \n",
        "                           padding='same', activation='relu')(decoder)\n",
        "decoder_conv = Conv2DTranspose(filters=8, kernel_size=3, strides=2, \n",
        "                           padding='same', activation='relu')(decoder)\n",
        "decoder_conv =  Conv2DTranspose(filters=num_channels, kernel_size=3, \n",
        "                          padding='same', activation='sigmoid')(decoder_conv)"
      ],
      "metadata": {
        "id": "NEw0HUlgabuG"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Connecting the encoder and decoder\n",
        "\n",
        "encoder = Model(encoder_input, latent_space)\n",
        "decoder = Model(decoder_input, decoder_conv)"
      ],
      "metadata": {
        "id": "80afg2wTbZaM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#still, the encoder and decoder part are not connected just yet. So we need to link the two in order to construct the entire VAE\n",
        "#output of vae model is the output of decoder in which its input is taken from the output of encoder\n",
        "vae = Model(encoder_input, decoder(encoder(encoder_input)))"
      ],
      "metadata": {
        "id": "IBoRT9XbbcgQ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The loss function for VAE\n",
        "def kl_reconstruction_loss(true, pred):\n",
        "    # Reconstruction loss (binary crossentropy)\n",
        "    reconstruction_loss = binary_crossentropy(K.flatten(true), K.flatten(pred)) * img_width * img_height\n",
        "\n",
        "    # KL divergence loss\n",
        "    kl_loss = 1 + sigma - K.square(mu) - K.exp(sigma)\n",
        "    kl_loss = K.sum(kl_loss, axis=-1)\n",
        "    kl_loss *= -0.5\n",
        "    # Total loss = 50% rec + 50% KL divergence loss\n",
        "    return K.mean(reconstruction_loss + kl_loss)"
      ],
      "metadata": {
        "id": "uAgQuAIcybsH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model using KL loss\n",
        "vae.compile(optimizer='adam', loss=kl_reconstruction_loss)"
      ],
      "metadata": {
        "id": "uRwDXir_cH4A"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training VAE\n",
        "history = vae.fit(x=X_train_new, y=X_train_new, epochs=10, batch_size=32, validation_data=(X_test_new,X_test_new))"
      ],
      "metadata": {
        "id": "9O5kW68HyJuK",
        "outputId": "ce86d076-073a-4a26-b61f-aafec713a1d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - ETA: 0s - loss: 181.2097"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r60000/60000 [==============================] - 49s 820us/sample - loss: 181.2097 - val_loss: 169.8791\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 43s 711us/sample - loss: 168.2523 - val_loss: 167.1095\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 47s 789us/sample - loss: 166.3878 - val_loss: 165.4754\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 40s 670us/sample - loss: 165.2976 - val_loss: 164.7062\n",
            "Epoch 5/10\n",
            " 2752/60000 [>.............................] - ETA: 36s - loss: 163.7202"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting loss value decrease\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])"
      ],
      "metadata": {
        "id": "X2zod1r3yo77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform images to points in latent space using encoder\n",
        "encoded = encoder.predict(X_train_new)\n"
      ],
      "metadata": {
        "id": "h469RfityrQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying images in latent space\n",
        "plt.figure(figsize=(14,12))\n",
        "plt.scatter(encoded[:,0], encoded[:,1], s=2, c=y_train, cmap='hsv')\n",
        "plt.colorbar()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bazBhyvny0KM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A function to display image sequence\n",
        "def display_image_sequence(x_start, y_start, x_end, y_end, no_of_imgs):\n",
        "    x_axis = np.linspace(x_start,x_end,no_of_imgs)\n",
        "    y_axis = np.linspace(y_start,y_end,no_of_imgs)\n",
        "    \n",
        "    x_axis = x_axis[:, np.newaxis]\n",
        "    y_axis = y_axis[:, np.newaxis]\n",
        "    \n",
        "    new_points = np.hstack((x_axis, y_axis))\n",
        "    new_images = decoder.predict(new_points)\n",
        "    new_images = new_images.reshape(new_images.shape[0], new_images.shape[1], new_images.shape[2])\n",
        "    \n",
        "    # Display some images\n",
        "    fig, axes = plt.subplots(ncols=no_of_imgs, sharex=False,\n",
        "                             sharey=True, figsize=(20, 7))\n",
        "    counter = 0\n",
        "    for i in range(no_of_imgs):\n",
        "        axes[counter].imshow(new_images[i], cmap='gray')\n",
        "        axes[counter].get_xaxis().set_visible(False)\n",
        "        axes[counter].get_yaxis().set_visible(False)\n",
        "        counter += 1\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "qCC_CHwSy0eX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying several new images\n",
        "# Starting point=(0,2), end point=(2,0)\n",
        "display_image_sequence(0,2,2,0,9)\n",
        "\n",
        "# Starting point=(-2,1), end point=(0,2)\n",
        "display_image_sequence(-2,1,0,2,9)\n",
        "\n",
        "# Starting point=(0,-2), end point=(0,2)\n",
        "display_image_sequence(0,-2,0,2,19)"
      ],
      "metadata": {
        "id": "x0DVpnajzGuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x6fPdQKHzLfW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}